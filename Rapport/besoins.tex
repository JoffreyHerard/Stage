\chapter{Analyse des besoins}

Dans cette troisième partie, il va être abordé l'ensemble des besoins qui permettront d'émettre un début de réponse par rapport au sujet et à la problématique.


\section{Plan d'expériences}

Après une analyse des besoins fonctionnels du projet, il va être détaillé chaque étapes du test.

\subsection{Sur les tests}

Lors de l'élaboration des tests qui seront exécutés il sera nécessaire de choisir précisément comment et grâce à quoi nous pourrons évaluer chaque composants. Rappelons également qu'il y aura un ensemble de scénarios à définir et qu'il faudra effectuer différentes variantes de tests pour chaque technologies de virtualisation, et de conteneurisation. Afin d'avoir des résultats cohérents, la neutralité de la sonde devra être importante. De plus, nous devrons définir la composante environnementale de chaque tests. Dès lors, on appellera "environnement" ce qui ne serait pas jugé comme influent à travers mes tests alors qu'il le sera. Prenons l'exemple de la vitesse du processeur, de sa température, ou encore de sa vitesse de connexion pour les tests réseaux. Bien entendu l'alimentation des composants peut varier et la politique de gestion des ressource vis à vis de chaque technologie de conteneurisation et d'hypervisions aussi.
Ainsi, pour chaque composant la question sera toujours la même, à savoir : 
\begin{center}
Que testons nous et pourquoi ? 
\end{center} 
Pour chaque composants détaillés ci-dessous, un schéma est en annexes concernant le détail du cheminement de chaque tests possibles pour chaque éléments.
\subsection{Expérimentation disque dur}
\subsubsection{Pourquoi tester le disque dur ? }
Le disque dur est sans aucun doute le membre de la machine le plus important pour le stockage de données. Il peut-être utilisé lors de l'enregistrement de fichiers, pour de l'écriture pure, l'enregistrement d'évènements locaux ou bien encore pour télécharger, assez simplement, des fichiers. D'un point de vue des utilisateurs, c'est le support de leurs usages, de leurs stockages d'informations. Ainsi, un utilisateur peut décider d'y stocker un ensemble de petits fichiers, de <<gros>> fichiers, voir de Tera-nesque fichiers.  
\subsubsection{Tester le disque dur sur quoi ?}
L'architecture de l'ordinateur à toute son importance pour les tests, notamment la taille des blocs pour l'écriture ou la lecture. Néanmoins, l'évaluation sur le test se fait-elle avec un accès en séquentiel ou en aléatoire ? De manière textuelle nous pouvons résumer cela ainsi : 
\begin{itemize}
\item Test de Performance en Écriture 
		\begin{enumerate}
		\item Évaluation des temps de réponses. 
		\item Évaluation des Vitesse de transfert.
		\item Évaluation de la meilleure performance possible (Maximum en vitesse écriture) sur des fichiers de différentes tailles.
		\end{enumerate}
\item Test de Performance en Lecture 
		\begin{enumerate}
		\item Évaluation des temps de réponses. 
		\item Évaluation de la meilleure performance possible (Maximum en vitesse lecture) sur des fichiers de différentes tailles. 
		\end{enumerate}
\item Évaluation des vitesse du cache.
\end{itemize}
%% FIGURE
\subsection{Expérimentation processeur}

\subsubsection{Pourquoi tester le processeur ? }
Le processeur peut être sollicité lors de calculs, notamment dans le cadre des hautes performances.
\subsubsection{Tester le processeur sur quoi ?  }
Un CPU peut être testé sur cette ensemble de choses-ci : 

\begin{itemize}
\item Évaluation de la vitesse de la lecture Mémoire. 
\item Évaluation de la vitesse de la écriture Mémoire. 
\item Évaluation de la vitesse de la copie Mémoire. 
\item Évaluation de la vitesse de calcul flottant à précision simple. 
\item Évaluation de la vitesse de calcul flottant à précision double.
\item Évaluation des opérations d'entrée sortie par secondes.
\item Évaluation des opérations de chiffrement. 
\item Évaluation des opérations de hachage.

\end{itemize}


\subsection{Expérimentation carte graphique}

\subsubsection{Pourquoi tester la carte graphique ? }

\subsubsection{Tester la carte graphique sur quoi ?  }

\begin{itemize}
\item Évaluation de la vitesse de la lecture Mémoire. 
\item Évaluation de la vitesse de la écriture Mémoire. 
\item Évaluation de la vitesse de la copie Mémoire. 
\item Évaluation de la vitesse de calcul flottant à précision simple. 
\item Évaluation de la vitesse de calcul flottant à précision double. 
\item Évaluation des opérations d'entrée sortie par secondes. 
\item Évaluation des opérations de chiffrement. 
\item Évaluation des opérations de hachage.

\end{itemize}

\subsection{Expérimentation réseaux}

\subsubsection{Pourquoi tester le réseaux ? }

\subsubsection{Tester le réseaux sur quoi ?  }

\begin{itemize}
\item Chaque tests doit être réalisés avec des paquets de taille croissante avec le temps.
\item Vitesse de téléchargement à estimer.
\item Vitesse d'envoi à estimer.
\end{itemize}

\section{Choix sur les outils de virtualisation}


Au vue des différentes définitions apportées précédemment il s'est avéré nécessaire de répartir nos tests sur l'ensemble des trois techonologies qui nous étaient accessibles afin de rester équitable dans notre démarche. Par conséquent, il faudra être cohérent dans nos choix et cela sans oublier que beaucoup ont, par effet de mode, abusé de l'utilisation des conteneurs. Nous avons alors décider d'étudier les outils Docker et LXC, assez populaires aujourd'hui. Pour commencer, il est nécessaire d'évaluer si Docker et LXC ont effectivement tous les points positifs qu'on leur vente. Docker étant basé sur LXC il serait intéressant d'évaluer si cette technologie, avec la couche apportée par Docker, a un vrai plus ou si cela est plutôt un moins. 
On a donc choisi d'évaluer la technologie de conteneurisation proposée par le conteneur Linux LXC et celle proposée par Docker. 
Parallèlement, nous pouvons partir du même constat pour les Hyperviseurs. Rappelons, qu'il en existe deux catégories : les types 1 \& 2 et il faudra donc établir des tests sur chacun d'eux. Tout comme nous l'avions fait pour Docker et LXC nous pouvons commencer par nous inéresser à leur popularité respective. Ainsi, il serait intéressant de prendre le logiciel d'Oracle VirtualBox qui est hyperviseur de type 2 utilisant des technologie comme celles de QEMU, hyperviseur du même type.  
Il reste tout de même à évaluer KVM, QEMU, Hyper-V et VMWare. Si nous le pouvions, il serait intéressant de comparer VMWare et Hyper-V car ils sont tous deux des acteurs importants dans les hyperviseurs d'aujourd'hui. De plus nous pourrions mettre en face à face QEMU, un hyperviseur de type 2 et VirtualBox. KVM est quant à lui un hyperviseur de type 1 intégré à Linux et utilisé dans Proxmox VE. En revanche, il semble essentiel de souligner que l'ensemble de nos évaluations dépendront des licences qui seront mises à notre disposition.
Pour conclure, il est indispensable de savoir discerner ce qui est pertinent de ce qui ne l'est pas et cela sans omettre de différencier les hyperviseurs étudiés. Je suis donc revenu sur mon précédent choix en admettant plus judicieux d'utiliser la technologie propre plutôt qu'une surcouche (comme proposé par M. Flauzac au cours de nos échanges). En effet, un test est intéressant sur la technologie mais si on agrémente les technologies du surcouche, cela en reste t-il tout aussi pertinent ? 
Par conséquent le choix s'oriente sur :
\begin{itemize}
\item LXC
\item Docker
\item KVM
\item QEMU
\item Hyper-V
\item VMWARE 
\end{itemize}
\begin{table}[h]
\centering
\caption{Solutions de virtualisations}
\label{Solution de virtualisations}
\begin{tabular}{|l|l|}
\hline
Conteneur & Hyperviseur \\ \hline
LXC       & KVM         \\
Docker    & QEMU        \\
          & Hyper-V     \\
          & VMWARE      \\ \hline
\end{tabular}
\end{table}
\newpage

\section{Choix d'outils d'évaluation}

Dans cette section nous étudierons les outils appelés "sonde" dans les paragraphes précédents. Pour commencer nous expliquerons en quoi ces outils permettent la répartition de tâches lorsqu'on souhaite exécuter une évaluation et nous parlerons ensuite de la récupération de ces données et de ce qui va être prélevé. 

\subsection{Outils d'évaluation personnel}

Après avoir observé les technologies de Provisionning et de test qu'il existait, nous nous sommes demandé s'il était pertinent d'avoir à développer un outil d'évaluations. Au vue de l'outil Phoronix, on s'est rendu compte que ce développement était compliqué et que nous n'aurions pas assez rapidement des résultats à exploiter. 

\subsection{Phoronix}
Il était alors nécessaire de choisir un outil d'évaluations conséquent. L'outil Phoronix est un outil de suite de tests réputé et il n'est plus à sa version d'essai. Historiquement, le 5 Juin 2008, la version 1.0 du Phoronix Test Suite était annoncée et il est aujourd'hui à sa septième version, plus précisement la 7.0.1. Ce logiciel a été publié sous licence GPLv3 et est conçu pour permettre aux utilisateurs de partager, leurs tests de logiciels et de matériel informatique via une interface graphique.
\newpage
\section{Choix d'outils d'orchestration}
Lors de ce stage il fallait pouvoir gérer un ensemble, suffisamment grand, de machines pour rendre le travail de scripting fastidieux. De plus, nous devions être capable de gérer le déploiement des machines virtuelles (KVM/QEMU et LXC/Docker) et provoquer l'exécution d'un ensemble de tests avant de les rapatrier sur les machines dites "maître". Nous avons alors utilisé quelques outils tels que Saltstack, Libvirt, Phoromatic.

\subsection{Saltstack}
L'outil Saltstack fonctionne avec une architecture Client/Serveur utilisant la technologie d'une file de messages ZeroMQ. Nous pouvons noter qu'il existe une autre technologie bien connue, celle de RabbitMQ. Vis à vis de son modèle Client/Serveur, Saltstack est dépendant d'une écoute de port et il a donc fallut envisager la possibilité de ports bloqués. Parallèlement, on appelle le serveur principal, qui émet les ordres, un "salt master" et les machines qui subissent les ordres des "salt minion". 

\subsubsection{Configuration Maître}
Si on souhaite modifier un ensemble de choses tels que le réseaux, les ressources, la sécurité, les modules, l'architectures des fichiers, et les logs éventuels il sera nécessaire de modifier, sur le serveur les fichiers correspondants à la location /etc/salt/master. Dans le cas du réseau on pourra y paramétrer les interfaces, les ports d'écoute et les timeouts. Pour les ressources on peut configurer un certain nombre de fichiers ouverts, un certain nombre de travaux, le cache, etc...
 
\subsubsection{Configuration Minion}

Il est nécessaire sur le client, de modifier les fichiers correspondants à la location /etc/salt/minion, on doit donc y paramétrer le nom du serveur, et son adresse. On peut y gérer, comme sur le master, un ensemble d'architecture de fichier, une gestion des modules, la sécurité et les logs.

\subsubsection{Détails sur le fonctionnement général}

Un minion/client doit s'enregistrer auprès du serveur/master pour pouvoir en subir les ordres. Toute fois le serveur doit être en mode "acceptation". Une fois les machines clientes acceptées sur le serveur, l'ensemble des opérations se déroulent avec la commande "salt" en désignant : les machines cibles, une commande, une fonction personnelle et un module à exécuter. 
 
\subsection{Phoromatic}
Le second outil Phoromatic a été proposé par la suite Phoronix, comme nous pouvons le deviner. C'est un serveur d'orchestration de lancement de tests réalisé en PHP et utilisant les web-sockets. Il nécessite un lancement sur la machine que l'on souhaite et requiert que chaque machines, visant à être évaluées, aient la suite de test Phoronix préalablement installée. On peut ensuite se connecter au serveur, grâce à une ligne de commande particulière, en lui spécifiant l'adresse, le port et le token associé. Cet outil nous permet alors de choisir la programmation des tests, autrement dit le support, la machine, le composant et l'heure que l'on souhaite. 

\subsection{Libvirt}

Libvirt est à lui seul un ensemble d'outils utiles dans la gestion de machines virtuelles et lorsque l'on souhaite exécuter une action sur celles-ci. Il est capable d'effectuer une gestion : du stockage, du réseau, d'une installation, de clonage de sauvegarde... 
L'Hôte des machines virtuelles, autrement dit la machine physique, y est alors appelé un "noeud". L'hyperviseur étant une couche logicielle de virtualisation avec des propriétés génériques et spécifiques, il s'exécute sur un "noeud". On note que Libvirt est capable de gérer un ensemble d'hyperviseur tel que : 
\begin{itemize}
\item XEN
\item Qemu/KVM
\item LXC
\item OpenVz
\item VirtualBox
\item VMware ESX Workstation Player
\item Hyper-V
\item IBM PowerVM
\item Virtuozzo
\item Bhyve
\end{itemize}
Le principe de Libvirt est de réaliser des opérations sur les domaines. N'ayant besoin que d'un hyperviseur et d'une adresse, la connexion à l'hyperviseur se fait par URL. L'exécution des commandes se fait en shell spécifique ou en commande shell paramétré avec un fichier XML. Libvirt est fondé sur une API écrite en : C, C++, C\#, Java, PHP, Python, Ruby.
\newpage
\section{Impact des services de virtualisation sur les performances et donc les résultats}
\subsection{Impact d'un Hyperviseur}
Le monde des Hyperviseurs étant assez vaste, chacun à une politique différente ne serait-ce que par le choix du type d'hyperviseur (Hyperviseur de type 1 \& 2). Par conséquent, il y a forcément des Hyperviseurs qui vont avoir une politique différente sur l'accès concurrent à des ressources. Ils ont besoin d'isoler les interruptions et les accès à la mémoire et cela est très coûteux au niveau des performances. Les surcoûts en termes de performances pour visualiser un système comportent trois aspects principaux : la virtualisation du processeur, de la mémoire, et des entrées/sorties. 

\subparagraph{Processeur}
L'utilisation d'un hyperviseur au-dessous du système d'exploitation diffère du schéma habituel où le système d'exploitation est l'entité la plus privilégiée dans le système. De nombreuses architectures de processeur ne fournissent que deux niveaux de privilèges. Dans une virtualisation efficace l'utilisation du processeur à des implications critiques sur les performances des autres caractéristiques du système. Dans l'évaluation des performances d'une machine virtuelle, les processus sont gérés par la machine virtuelle à la place du système d'exploitation sous-jacent. Les threads émulés des environnements multi-thread, en dehors des capacités du système d'exploitation d'origine, sont gérés dans l'espace utilisateur à la place de l'espace noyau, permettant le travail avec des environnements sans support natif des threads. De bonnes performances sur un microprocesseur multi-cœur sont obtenues grâce à l'implémentation de threads natifs pouvant attribuer automatiquement le travail à plusieurs processeurs, ils permettent un démarrage plus rapide de processus sur certaines machines virtuelles.

\subsection{Impact d'un conteneur}
A la base, le concept de conteneurisation permet aux instances virtuelles de partager un système d'exploitation hôte unique, avec ses fichiers binaires, bibliothèques ou pilotes. 
Cette approche réduit le gaspillage des ressources car chaque conteneurs ne renferme que l'application et les fichiers binaires ou bibliothèques associés. On utilise donc le même système d'exploitation (OS) hôte pour plusieurs conteneurs, au lieu d'installer un OS (et d'en acheter la licence) pour chaque VM invitée. Le conteneur de chaque application étant libéré de la charge d'un OS, il est nettement plus petit, plus facile à migrer ou à télécharger, plus rapide à sauvegarder ou à restaurer. Enfin, il exige moins de mémoire. La conteneurisation permet au serveur d'héberger potentiellement beaucoup plus de conteneurs que s'il s'agissait de machines virtuelles. La différence en termes d'occupation peut être considérable, car un serveur donné accueillera de 10 à 100 fois plus d'instances de conteneur que d'instances d'application sur VM.
